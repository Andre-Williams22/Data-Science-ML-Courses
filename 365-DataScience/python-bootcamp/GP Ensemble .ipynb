{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import itertools \n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.ensemble import IoslationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from statsmodels.tsa.api import ExponentialSmoothing \n",
    "import statsmodels.api as sm \n",
    "from fbprophet import Prophet \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_anomaliesOutput= loaded data\n",
    "gp_traindata=loaded data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_anomalies(gp_traindata):\n",
    "    max_dt = gp_traindata.select('dt_period_end')\\\n",
    "    .agg(F.max('dt_period_end'))\n",
    "    .collect()[0][0]\n",
    "    \n",
    "    in_cols = ['starting_base', 'actual', 'is_anomaly', 'gp_prediction', 'excess']\n",
    "    metric='vol'\n",
    "    feats = ['dt_period_end', 'dat_of_week', metric, metric+'_weight']\n",
    "    \n",
    "    schema_cols = ['starting_base', 'actual', 'is_anomaly', 'gp_prediction', 'excess']\n",
    "    run_model_udf = F.udf(lambda x: run_model(x, metric, max_dt))\n",
    "    \n",
    "    anomaly_df = gp_traindata.withColumn('features', F.struct(feats + ['starting_base'])) \\\n",
    "                            .select(in_cols) \\\n",
    "                            .groupBy(in_cols[:-1])\\\n",
    "                            .agg(F.collect_list('features').alias('collected_features'))\\\n",
    "                            .withColumn('anomaly_struct', run_model_udf())\n",
    "    \n",
    "    return anomaly_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X, metric, max_dt):\n",
    "    cols = ['dt_period_end', 'day_of_week', metric, metric+'_weight', 'starting_base']\n",
    "    X_train = pd.DataFrame(X, columns=cols)\n",
    "    X_train.sort_values('dt_period_end', inplace=True)\n",
    "    if len(X_train) == 0:\n",
    "        return '0, 0, 0, 0, 0'\n",
    "    X_train.fillna(0, inplace=True)\n",
    "    X_train[metric] = X_train[metric].map(lambda x: 1 if x <= 0 else x)\n",
    "    print(X_train.columns)\n",
    "    try:\n",
    "        actual = X_train[X_train['dt_period_end'] == max_dt][metric].iloc[0]\n",
    "        starting_base = X_train[X_train['dt_period_end']==max_dt]['starting_base'].iloc[0]\n",
    "    except:\n",
    "        actual, starting_base = (0,0)\n",
    "    if starting_base < 1000:\n",
    "        return ', '.join(map(str, [starting_base, actual])) + ', 0, 0, 0'\n",
    "    X_train.drop('starting_base', axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    ### model functional call dict\n",
    "    total_models = len(clfs)\n",
    "    model_vote_sum = 0\n",
    "    model_forecast_pos = []\n",
    "    model_forecast_neg = []\n",
    "    \n",
    "    model_func_dict = {\"IF\": gp_model_if, 'svm':gp_model_onesvm, 'LOF':gp_model_lof,\n",
    "                       'HWES': gp_model_hwes, 'SARIMAX': gp_model_sarima, 'FBPROP':gp_model_fbprophet}\n",
    "    \n",
    "    for clf in clfs:\n",
    "        anomaly, forecast = model_func_dict[clf](X_train, metric, max_dt)\n",
    "        model_vote_sum += int(anomaly)\n",
    "        if anomaly:\n",
    "            model_forecast_pos.append(forecast)\n",
    "        else:\n",
    "            model_forecast_neg.append(forecast)\n",
    "    mean_pos = np.mean(model_forecast_pos)\n",
    "    mean_neg = np.mean(model_forecast_neg)\n",
    "    if model_vote_sum > int(total_models/2):\n",
    "        return ', '.join(map(str, [starting_base, actual, 1, mean_pos, actual-mean_pos]))\n",
    "    return ', '.join(map(str, [starting_base, actual, 0, mean_neg, actual - mean_neg]))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_model_fbprophet(df, metric, max_dt):\n",
    "    df.sort_values(by=['dt_period_end'], inplace=True, ascending=False)\n",
    "    df = df[['dt_period_end', metric]][:-1]\n",
    "    df.columns = ['ds', 'y']\n",
    "    # instantiate model\n",
    "    m = Prophet(daily_seasonality=True, yearly_seasonality=True, seasonality_mode='multiplicative')\n",
    "    m.fit(df)\n",
    "    \n",
    "    future = m.make_future_dataframe(periods=1, freq='D')\n",
    "    forecast = m.predict(future)\n",
    "    \n",
    "    forecast['Actual'] = df['y'].reset_index(drop=True)\n",
    "    \n",
    "    forecasted = forecast[['ds', 'yhat', 'Actual', 'yhat_lower', 'yhat_upper']].copy()\n",
    "    \n",
    "    forecasted['errors'] = forecasted['Actual'] - forecasted['yhat']\n",
    "    \n",
    "    forecasted['ambiguity'] = forecasted['yhat_upper'] - forecasted['yhat_lower']\n",
    "    \n",
    "    forecasted[forecasted['errors']>1.5*forecasted['ambiguity']]\n",
    "    forecasted['anomaly'] = forecasted.apply(lambda x:1 if (x['errors'] > 1.5*x['ambiguity'] else 0, axis=1))\n",
    "    \n",
    "    # importance \n",
    "    ##\n",
    "    ##\n",
    "    try:\n",
    "        return forecasted[forecasted['ds']==max_dt]['anomaly'].iloc[0] ==1, forecasted[forecasted['ds']==max_dt]['yhat'].iloc[-1]\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_model_lof(df, metric, max_dt):\n",
    "    X_train = pd.concat([df, pd.get_dummies(df['day_of_week'], prefix='day')], axis=1)\n",
    "    if_features = features + [metric]\n",
    "    \n",
    "    model = LocalOutlierFacotr(contamination='auto', n_neighbors=20, novely=False)\n",
    "    \n",
    "    df['anomaly'] = pd.Series(model.fit_predict(X_train[if_features]))\n",
    "    \n",
    "    df['anomaly'].replace({1:0, -1:1}, inplace=True)\n",
    "    \n",
    "    try:\n",
    "        return df[df['dt_period_end']==max_dt]['anomaly'].iloc[0] == 1\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
